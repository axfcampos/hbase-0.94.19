<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1" />
<title>TableSnapshotInputFormat xref</title>
<link type="text/css" rel="stylesheet" href="../../../../../stylesheet.css" />
</head>
<body>
<div id="overview"><a href="../../../../../../apidocs/org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">View Javadoc</a></div><pre>

<a name="1" href="#1">1</a>   <em class="jxr_javadoccomment">/**</em>
<a name="2" href="#2">2</a>   <em class="jxr_javadoccomment"> * Licensed to the Apache Software Foundation (ASF) under one</em>
<a name="3" href="#3">3</a>   <em class="jxr_javadoccomment"> * or more contributor license agreements.  See the NOTICE file</em>
<a name="4" href="#4">4</a>   <em class="jxr_javadoccomment"> * distributed with this work for additional information</em>
<a name="5" href="#5">5</a>   <em class="jxr_javadoccomment"> * regarding copyright ownership.  The ASF licenses this file</em>
<a name="6" href="#6">6</a>   <em class="jxr_javadoccomment"> * to you under the Apache License, Version 2.0 (the</em>
<a name="7" href="#7">7</a>   <em class="jxr_javadoccomment"> * "License"); you may not use this file except in compliance</em>
<a name="8" href="#8">8</a>   <em class="jxr_javadoccomment"> * with the License.  You may obtain a copy of the License at</em>
<a name="9" href="#9">9</a>   <em class="jxr_javadoccomment"> *</em>
<a name="10" href="#10">10</a>  <em class="jxr_javadoccomment"> *     <a href="http://www.apache.org/licenses/LICENSE-2.0" target="alexandria_uri">http://www.apache.org/licenses/LICENSE-2.0</a></em>
<a name="11" href="#11">11</a>  <em class="jxr_javadoccomment"> *</em>
<a name="12" href="#12">12</a>  <em class="jxr_javadoccomment"> * Unless required by applicable law or agreed to in writing, software</em>
<a name="13" href="#13">13</a>  <em class="jxr_javadoccomment"> * distributed under the License is distributed on an "AS IS" BASIS,</em>
<a name="14" href="#14">14</a>  <em class="jxr_javadoccomment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</em>
<a name="15" href="#15">15</a>  <em class="jxr_javadoccomment"> * See the License for the specific language governing permissions and</em>
<a name="16" href="#16">16</a>  <em class="jxr_javadoccomment"> * limitations under the License.</em>
<a name="17" href="#17">17</a>  <em class="jxr_javadoccomment"> */</em>
<a name="18" href="#18">18</a>  
<a name="19" href="#19">19</a>  <strong class="jxr_keyword">package</strong> org.apache.hadoop.hbase.mapreduce;
<a name="20" href="#20">20</a>  
<a name="21" href="#21">21</a>  <strong class="jxr_keyword">import</strong> java.io.DataInput;
<a name="22" href="#22">22</a>  <strong class="jxr_keyword">import</strong> java.io.DataOutput;
<a name="23" href="#23">23</a>  <strong class="jxr_keyword">import</strong> java.io.IOException;
<a name="24" href="#24">24</a>  <strong class="jxr_keyword">import</strong> java.lang.reflect.Method;
<a name="25" href="#25">25</a>  <strong class="jxr_keyword">import</strong> java.util.ArrayList;
<a name="26" href="#26">26</a>  <strong class="jxr_keyword">import</strong> java.util.List;
<a name="27" href="#27">27</a>  <strong class="jxr_keyword">import</strong> java.util.Set;
<a name="28" href="#28">28</a>  
<a name="29" href="#29">29</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.Log;
<a name="30" href="#30">30</a>  <strong class="jxr_keyword">import</strong> org.apache.commons.logging.LogFactory;
<a name="31" href="#31">31</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.conf.Configuration;
<a name="32" href="#32">32</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.FileSystem;
<a name="33" href="#33">33</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.fs.Path;
<a name="34" href="#34">34</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HConstants;
<a name="35" href="#35">35</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HDFSBlocksDistribution;
<a name="36" href="#36">36</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HDFSBlocksDistribution.HostAndWeight;
<a name="37" href="#37">37</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HRegionInfo;
<a name="38" href="#38">38</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.HTableDescriptor;
<a name="39" href="#39">39</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.KeyValue;
<a name="40" href="#40">40</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.IsolationLevel;
<a name="41" href="#41">41</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.Result;
<a name="42" href="#42">42</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.Scan;
<a name="43" href="#43">43</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.client.metrics.ScanMetrics;
<a name="44" href="#44">44</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.errorhandling.ForeignExceptionDispatcher;
<a name="45" href="#45">45</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.io.ImmutableBytesWritable;
<a name="46" href="#46">46</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.monitoring.MonitoredTask;
<a name="47" href="#47">47</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.monitoring.TaskMonitor;
<a name="48" href="#48">48</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription;
<a name="49" href="#49">49</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.HRegion;
<a name="50" href="#50">50</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.regionserver.RegionScanner;
<a name="51" href="#51">51</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.snapshot.RestoreSnapshotHelper;
<a name="52" href="#52">52</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.snapshot.SnapshotDescriptionUtils;
<a name="53" href="#53">53</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.snapshot.SnapshotReferenceUtil;
<a name="54" href="#54">54</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.Bytes;
<a name="55" href="#55">55</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.hbase.util.FSTableDescriptors;
<a name="56" href="#56">56</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.Text;
<a name="57" href="#57">57</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.io.Writable;
<a name="58" href="#58">58</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.Counter;
<a name="59" href="#59">59</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.InputFormat;
<a name="60" href="#60">60</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.InputSplit;
<a name="61" href="#61">61</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.Job;
<a name="62" href="#62">62</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.JobContext;
<a name="63" href="#63">63</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.RecordReader;
<a name="64" href="#64">64</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.mapreduce.TaskAttemptContext;
<a name="65" href="#65">65</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.metrics.util.MetricsTimeVaryingLong;
<a name="66" href="#66">66</a>  <strong class="jxr_keyword">import</strong> org.apache.hadoop.util.StringUtils;
<a name="67" href="#67">67</a>  
<a name="68" href="#68">68</a>  <strong class="jxr_keyword">import</strong> com.google.common.annotations.VisibleForTesting;
<a name="69" href="#69">69</a>  
<a name="70" href="#70">70</a>  <em class="jxr_javadoccomment">/**</em>
<a name="71" href="#71">71</a>  <em class="jxr_javadoccomment"> * TableSnapshotInputFormat allows a MapReduce job to run over a table snapshot. The</em>
<a name="72" href="#72">72</a>  <em class="jxr_javadoccomment"> * job bypasses HBase servers, and directly accesses the underlying files</em>
<a name="73" href="#73">73</a>  <em class="jxr_javadoccomment"> * (hfile, recovered edits, hlogs, etc) directly to provide maximum performance.</em>
<a name="74" href="#74">74</a>  <em class="jxr_javadoccomment"> * The snapshot is not required to be restored or cloned. This also allows to</em>
<a name="75" href="#75">75</a>  <em class="jxr_javadoccomment"> * run the mapreduce job from an online or offline hbase cluster. The snapshot</em>
<a name="76" href="#76">76</a>  <em class="jxr_javadoccomment"> * files can be exported by using the ExportSnapshot tool, to a pure-hdfs</em>
<a name="77" href="#77">77</a>  <em class="jxr_javadoccomment"> * cluster, and this InputFormat can be used to run the mapreduce job directly</em>
<a name="78" href="#78">78</a>  <em class="jxr_javadoccomment"> * over the snapshot files.</em>
<a name="79" href="#79">79</a>  <em class="jxr_javadoccomment"> * &lt;p&gt;</em>
<a name="80" href="#80">80</a>  <em class="jxr_javadoccomment"> * Usage is similar to TableInputFormat.</em>
<a name="81" href="#81">81</a>  <em class="jxr_javadoccomment"> * {@link TableMapReduceUtil#initTableSnapshotMapperJob(String, Scan, Class, Class, Class, Job,</em>
<a name="82" href="#82">82</a>  <em class="jxr_javadoccomment"> * boolean, Path)} can be used to configure the job.</em>
<a name="83" href="#83">83</a>  <em class="jxr_javadoccomment"> * </em>
<a name="84" href="#84">84</a>  <em class="jxr_javadoccomment"> * &lt;pre&gt;</em>
<a name="85" href="#85">85</a>  <em class="jxr_javadoccomment"> * {</em>
<a name="86" href="#86">86</a>  <em class="jxr_javadoccomment"> *   &amp;#064;code</em>
<a name="87" href="#87">87</a>  <em class="jxr_javadoccomment"> *   Job job = new Job(conf);</em>
<a name="88" href="#88">88</a>  <em class="jxr_javadoccomment"> *   Scan scan = new Scan();</em>
<a name="89" href="#89">89</a>  <em class="jxr_javadoccomment"> *   TableMapReduceUtil.initSnapshotMapperJob(snapshotName, scan,</em>
<a name="90" href="#90">90</a>  <em class="jxr_javadoccomment"> *       MyTableMapper.class, MyMapKeyOutput.class,</em>
<a name="91" href="#91">91</a>  <em class="jxr_javadoccomment"> *       MyMapOutputValueWritable.class, job, true, tmpDir);</em>
<a name="92" href="#92">92</a>  <em class="jxr_javadoccomment"> * }</em>
<a name="93" href="#93">93</a>  <em class="jxr_javadoccomment"> * &lt;/pre&gt;</em>
<a name="94" href="#94">94</a>  <em class="jxr_javadoccomment"> * &lt;p&gt;</em>
<a name="95" href="#95">95</a>  <em class="jxr_javadoccomment"> * Internally, this input format restores the snapshot into the given tmp</em>
<a name="96" href="#96">96</a>  <em class="jxr_javadoccomment"> * directory. Similar to {@link TableInputFormat} an {@link InputSplit} is created per region.</em>
<a name="97" href="#97">97</a>  <em class="jxr_javadoccomment"> * The region is opened for reading from each RecordReader. An internal</em>
<a name="98" href="#98">98</a>  <em class="jxr_javadoccomment"> * RegionScanner is used to execute the Scan obtained from the user.</em>
<a name="99" href="#99">99</a>  <em class="jxr_javadoccomment"> * &lt;p&gt;</em>
<a name="100" href="#100">100</a> <em class="jxr_javadoccomment"> * &lt;p&gt;</em>
<a name="101" href="#101">101</a> <em class="jxr_javadoccomment"> * HBase owns all the data and snapshot files on the filesystem. Only the HBase user can read from</em>
<a name="102" href="#102">102</a> <em class="jxr_javadoccomment"> * snapshot files and data files. HBase also enforces security because all the requests are handled</em>
<a name="103" href="#103">103</a> <em class="jxr_javadoccomment"> * by the server layer, and the user cannot read from the data files directly. </em>
<a name="104" href="#104">104</a> <em class="jxr_javadoccomment"> * To read from snapshot files directly from the file system, the user who is running the MR job </em>
<a name="105" href="#105">105</a> <em class="jxr_javadoccomment"> * must have sufficient permissions to access snapshot and reference files. </em>
<a name="106" href="#106">106</a> <em class="jxr_javadoccomment"> * This means that to run mapreduce over snapshot files, the MR job has to be run as the HBase </em>
<a name="107" href="#107">107</a> <em class="jxr_javadoccomment"> * user or the user must have group or other priviledges in the filesystem (See HBASE-8369). </em>
<a name="108" href="#108">108</a> <em class="jxr_javadoccomment"> * Note that, given other users access to read from snapshot/data files will completely circumvent </em>
<a name="109" href="#109">109</a> <em class="jxr_javadoccomment"> * the access control enforced by HBase.</em>
<a name="110" href="#110">110</a> <em class="jxr_javadoccomment"> */</em>
<a name="111" href="#111">111</a> <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotInputFormat</a> <strong class="jxr_keyword">extends</strong>
<a name="112" href="#112">112</a>     InputFormat&lt;ImmutableBytesWritable, Result&gt; {
<a name="113" href="#113">113</a>   <em class="jxr_comment">// TODO: Snapshots files are owned in fs by the hbase user. There is no</em>
<a name="114" href="#114">114</a>   <em class="jxr_comment">// easy way to delegate access.</em>
<a name="115" href="#115">115</a> 
<a name="116" href="#116">116</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String SNAPSHOT_NAME_KEY = <span class="jxr_string">"hbase.mr.snapshot.input.name"</span>;
<a name="117" href="#117">117</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String TABLE_DIR_KEY = <span class="jxr_string">"hbase.mr.snapshot.input.table.dir"</span>;
<a name="118" href="#118">118</a> 
<a name="119" href="#119">119</a>   <em class="jxr_javadoccomment">/**</em><em class="jxr_javadoccomment"> See {@link #getBestLocations(Configuration, HDFSBlocksDistribution)} */</em>
<a name="120" href="#120">120</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String LOCALITY_CUTOFF_MULTIPLIER = 
<a name="121" href="#121">121</a>       <span class="jxr_string">"hbase.tablesnapshotinputformat.locality.cutoff.multiplier"</span>;
<a name="122" href="#122">122</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">float</strong> DEFAULT_LOCALITY_CUTOFF_MULTIPLIER = 0.8f;
<a name="123" href="#123">123</a> 
<a name="124" href="#124">124</a>   <em class="jxr_javadoccomment">/**</em>
<a name="125" href="#125">125</a> <em class="jxr_javadoccomment">   * Snapshot region split.</em>
<a name="126" href="#126">126</a> <em class="jxr_javadoccomment">   */</em>
<a name="127" href="#127">127</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionSplit</a> <strong class="jxr_keyword">extends</strong> InputSplit implements
<a name="128" href="#128">128</a>       Writable {
<a name="129" href="#129">129</a>     <strong class="jxr_keyword">private</strong> String regionName;
<a name="130" href="#130">130</a>     <strong class="jxr_keyword">private</strong> String[] locations;
<a name="131" href="#131">131</a> 
<a name="132" href="#132">132</a>     <em class="jxr_javadoccomment">/**</em>
<a name="133" href="#133">133</a> <em class="jxr_javadoccomment">     * Constructor for serialization.</em>
<a name="134" href="#134">134</a> <em class="jxr_javadoccomment">     */</em>
<a name="135" href="#135">135</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionSplit</a>() {
<a name="136" href="#136">136</a>     }
<a name="137" href="#137">137</a> 
<a name="138" href="#138">138</a>     <em class="jxr_javadoccomment">/**</em>
<a name="139" href="#139">139</a> <em class="jxr_javadoccomment">     * Constructor.</em>
<a name="140" href="#140">140</a> <em class="jxr_javadoccomment">     * </em>
<a name="141" href="#141">141</a> <em class="jxr_javadoccomment">     * @param regionName</em>
<a name="142" href="#142">142</a> <em class="jxr_javadoccomment">     *          Region name</em>
<a name="143" href="#143">143</a> <em class="jxr_javadoccomment">     * @param locationList</em>
<a name="144" href="#144">144</a> <em class="jxr_javadoccomment">     *          List of nodes with the region's HDFS blocks, in descending order</em>
<a name="145" href="#145">145</a> <em class="jxr_javadoccomment">     *          of weight</em>
<a name="146" href="#146">146</a> <em class="jxr_javadoccomment">     */</em>
<a name="147" href="#147">147</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionSplit</a>(<strong class="jxr_keyword">final</strong> String regionName,
<a name="148" href="#148">148</a>         <strong class="jxr_keyword">final</strong> List&lt;String&gt; locationList) {
<a name="149" href="#149">149</a>       <strong class="jxr_keyword">this</strong>.regionName = regionName;
<a name="150" href="#150">150</a> 
<a name="151" href="#151">151</a>       <em class="jxr_comment">// only use the top node</em>
<a name="152" href="#152">152</a>       List&lt;String&gt; list = locationList.size() &gt; 1 ? locationList.subList(0, 1)
<a name="153" href="#153">153</a>           : locationList;
<a name="154" href="#154">154</a>       <strong class="jxr_keyword">this</strong>.locations = list.toArray(<strong class="jxr_keyword">new</strong> String[list.size()]);
<a name="155" href="#155">155</a>     }
<a name="156" href="#156">156</a> 
<a name="157" href="#157">157</a>     @Override
<a name="158" href="#158">158</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">long</strong> getLength() <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="159" href="#159">159</a>       <strong class="jxr_keyword">return</strong> locations.length;
<a name="160" href="#160">160</a>     }
<a name="161" href="#161">161</a> 
<a name="162" href="#162">162</a>     @Override
<a name="163" href="#163">163</a>     <strong class="jxr_keyword">public</strong> String[] getLocations() <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="164" href="#164">164</a>       <strong class="jxr_keyword">return</strong> locations;
<a name="165" href="#165">165</a>     }
<a name="166" href="#166">166</a> 
<a name="167" href="#167">167</a>     @Override
<a name="168" href="#168">168</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> readFields(DataInput in) <strong class="jxr_keyword">throws</strong> IOException {
<a name="169" href="#169">169</a>       regionName = Text.readString(in);
<a name="170" href="#170">170</a>       <strong class="jxr_keyword">int</strong> locLength = in.readInt();
<a name="171" href="#171">171</a>       locations = <strong class="jxr_keyword">new</strong> String[locLength];
<a name="172" href="#172">172</a>       <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 0; i &lt; locLength; i++) {
<a name="173" href="#173">173</a>         locations[i] = Text.readString(in);
<a name="174" href="#174">174</a>       }
<a name="175" href="#175">175</a>     }
<a name="176" href="#176">176</a> 
<a name="177" href="#177">177</a>     @Override
<a name="178" href="#178">178</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> write(DataOutput out) <strong class="jxr_keyword">throws</strong> IOException {
<a name="179" href="#179">179</a>       Text.writeString(out, regionName);
<a name="180" href="#180">180</a>       out.writeInt(locations.length);
<a name="181" href="#181">181</a>       <strong class="jxr_keyword">for</strong> (String l : locations) {
<a name="182" href="#182">182</a>         Text.writeString(out, l);
<a name="183" href="#183">183</a>       }
<a name="184" href="#184">184</a>     }
<a name="185" href="#185">185</a>   }
<a name="186" href="#186">186</a> 
<a name="187" href="#187">187</a>   <em class="jxr_javadoccomment">/**</em>
<a name="188" href="#188">188</a> <em class="jxr_javadoccomment">   * Snapshot region record reader.</em>
<a name="189" href="#189">189</a> <em class="jxr_javadoccomment">   */</em>
<a name="190" href="#190">190</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> <strong class="jxr_keyword">class</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionRecordReader</a> <strong class="jxr_keyword">extends</strong>
<a name="191" href="#191">191</a>       RecordReader&lt;ImmutableBytesWritable, Result&gt; {
<a name="192" href="#192">192</a>     <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> Log LOG = LogFactory.getLog(TableSnapshotRegionRecordReader.<strong class="jxr_keyword">class</strong>);
<a name="193" href="#193">193</a> 
<a name="194" href="#194">194</a>     <em class="jxr_comment">// HBASE_COUNTER_GROUP_NAME is the name of mapreduce counter group for HBase</em>
<a name="195" href="#195">195</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">final</strong> String HBASE_COUNTER_GROUP_NAME = <span class="jxr_string">"HBase Counters"</span>;
<a name="196" href="#196">196</a> 
<a name="197" href="#197">197</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionSplit</a> split;
<a name="198" href="#198">198</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/HRegion.html">HRegion</a> region;
<a name="199" href="#199">199</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan;
<a name="200" href="#200">200</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/RegionScanner.html">RegionScanner</a> scanner;
<a name="201" href="#201">201</a>     <strong class="jxr_keyword">private</strong> List&lt;KeyValue&gt; values;
<a name="202" href="#202">202</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Result.html">Result</a> result = <strong class="jxr_keyword">null</strong>;
<a name="203" href="#203">203</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/io/ImmutableBytesWritable.html">ImmutableBytesWritable</a> row = <strong class="jxr_keyword">null</strong>;
<a name="204" href="#204">204</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> more;
<a name="205" href="#205">205</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/client/metrics/ScanMetrics.html">ScanMetrics</a> scanMetrics = <strong class="jxr_keyword">null</strong>;
<a name="206" href="#206">206</a>     <strong class="jxr_keyword">private</strong> TaskAttemptContext context = <strong class="jxr_keyword">null</strong>;
<a name="207" href="#207">207</a>     <strong class="jxr_keyword">private</strong> Method getCounter = <strong class="jxr_keyword">null</strong>;
<a name="208" href="#208">208</a> 
<a name="209" href="#209">209</a>     @Override
<a name="210" href="#210">210</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> initialize(<strong class="jxr_keyword">final</strong> InputSplit aSplit,
<a name="211" href="#211">211</a>         <strong class="jxr_keyword">final</strong> TaskAttemptContext context) <strong class="jxr_keyword">throws</strong> IOException,
<a name="212" href="#212">212</a>         InterruptedException {
<a name="213" href="#213">213</a>       Configuration conf = context.getConfiguration();
<a name="214" href="#214">214</a>       <strong class="jxr_keyword">this</strong>.split = (TableSnapshotRegionSplit) aSplit;
<a name="215" href="#215">215</a> 
<a name="216" href="#216">216</a>       Path rootDir = <strong class="jxr_keyword">new</strong> Path(conf.get(HConstants.HBASE_DIR));
<a name="217" href="#217">217</a>       FileSystem fs = rootDir.getFileSystem(conf);
<a name="218" href="#218">218</a> 
<a name="219" href="#219">219</a>       String snapshotName = getSnapshotName(conf);
<a name="220" href="#220">220</a>       Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(
<a name="221" href="#221">221</a>           snapshotName, rootDir);
<a name="222" href="#222">222</a> 
<a name="223" href="#223">223</a>       <em class="jxr_comment">// load region descriptor</em>
<a name="224" href="#224">224</a>       String regionName = <strong class="jxr_keyword">this</strong>.split.regionName;
<a name="225" href="#225">225</a>       Path regionDir = <strong class="jxr_keyword">new</strong> Path(snapshotDir, regionName);
<a name="226" href="#226">226</a>       <a href="../../../../../org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a> hri = HRegion.loadDotRegionInfoFileContent(fs, regionDir);
<a name="227" href="#227">227</a> 
<a name="228" href="#228">228</a>       <em class="jxr_comment">// create scan</em>
<a name="229" href="#229">229</a>       scan = TableMapReduceUtil.convertStringToScan(conf.get(TableInputFormat.SCAN));
<a name="230" href="#230">230</a>       <em class="jxr_comment">// region is immutable, this should be fine, otherwise we have to set the</em>
<a name="231" href="#231">231</a>       <em class="jxr_comment">// thread read point...</em>
<a name="232" href="#232">232</a>       scan.setIsolationLevel(IsolationLevel.READ_UNCOMMITTED);
<a name="233" href="#233">233</a>       scan.setCacheBlocks(false);
<a name="234" href="#234">234</a> 
<a name="235" href="#235">235</a>       <em class="jxr_comment">// load table descriptor</em>
<a name="236" href="#236">236</a>       <a href="../../../../../org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a> htd = FSTableDescriptors.getTableDescriptor(fs,
<a name="237" href="#237">237</a>           snapshotDir);
<a name="238" href="#238">238</a>       Path tableDir = <strong class="jxr_keyword">new</strong> Path(conf.get(TABLE_DIR_KEY));
<a name="239" href="#239">239</a> 
<a name="240" href="#240">240</a>       <em class="jxr_comment">// open region from the snapshot directory</em>
<a name="241" href="#241">241</a>       <strong class="jxr_keyword">this</strong>.region = openRegion(tableDir, fs, conf, hri, htd);
<a name="242" href="#242">242</a> 
<a name="243" href="#243">243</a>       <em class="jxr_comment">// create region scanner</em>
<a name="244" href="#244">244</a>       <strong class="jxr_keyword">this</strong>.scanner = region.getScanner(scan);
<a name="245" href="#245">245</a>       values = <strong class="jxr_keyword">new</strong> ArrayList&lt;KeyValue&gt;();
<a name="246" href="#246">246</a>       <strong class="jxr_keyword">this</strong>.more = <strong class="jxr_keyword">true</strong>;
<a name="247" href="#247">247</a>       <strong class="jxr_keyword">this</strong>.scanMetrics = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/metrics/ScanMetrics.html">ScanMetrics</a>();
<a name="248" href="#248">248</a> 
<a name="249" href="#249">249</a>       <strong class="jxr_keyword">if</strong> (context != <strong class="jxr_keyword">null</strong>) {
<a name="250" href="#250">250</a>         <strong class="jxr_keyword">this</strong>.context = context;
<a name="251" href="#251">251</a>         getCounter = retrieveGetCounterWithStringsParams(context);
<a name="252" href="#252">252</a>       }
<a name="253" href="#253">253</a>       region.startRegionOperation();
<a name="254" href="#254">254</a>     }
<a name="255" href="#255">255</a> 
<a name="256" href="#256">256</a>     <strong class="jxr_keyword">private</strong> <a href="../../../../../org/apache/hadoop/hbase/regionserver/HRegion.html">HRegion</a> openRegion(<strong class="jxr_keyword">final</strong> Path tableDir, <strong class="jxr_keyword">final</strong> FileSystem fs,
<a name="257" href="#257">257</a>         <strong class="jxr_keyword">final</strong> Configuration conf, <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a> hri,
<a name="258" href="#258">258</a>         <strong class="jxr_keyword">final</strong> <a href="../../../../../org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a> htd) <strong class="jxr_keyword">throws</strong> IOException {
<a name="259" href="#259">259</a>       <a href="../../../../../org/apache/hadoop/hbase/regionserver/HRegion.html">HRegion</a> r = HRegion.newHRegion(tableDir, <strong class="jxr_keyword">null</strong>, fs, conf, hri, htd, <strong class="jxr_keyword">null</strong>);
<a name="260" href="#260">260</a>       r.initialize(<strong class="jxr_keyword">null</strong>);
<a name="261" href="#261">261</a>       <strong class="jxr_keyword">return</strong> r;
<a name="262" href="#262">262</a>     }
<a name="263" href="#263">263</a> 
<a name="264" href="#264">264</a>     @Override
<a name="265" href="#265">265</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">boolean</strong> nextKeyValue() <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="266" href="#266">266</a>       values.clear();
<a name="267" href="#267">267</a>       <em class="jxr_comment">// RegionScanner.next() has a different contract than</em>
<a name="268" href="#268">268</a>       <em class="jxr_comment">// RecordReader.nextKeyValue(). Scanner</em>
<a name="269" href="#269">269</a>       <em class="jxr_comment">// indicates no value read by returning empty results. Returns boolean</em>
<a name="270" href="#270">270</a>       <em class="jxr_comment">// indicates if more</em>
<a name="271" href="#271">271</a>       <em class="jxr_comment">// rows exist AFTER this one</em>
<a name="272" href="#272">272</a>       <strong class="jxr_keyword">if</strong> (!more) {
<a name="273" href="#273">273</a>         updateCounters();
<a name="274" href="#274">274</a>         <strong class="jxr_keyword">return</strong> false;
<a name="275" href="#275">275</a>       }
<a name="276" href="#276">276</a>       more = scanner.nextRaw(values, scan.getBatch(), <strong class="jxr_keyword">null</strong>);
<a name="277" href="#277">277</a>       <strong class="jxr_keyword">if</strong> (values.isEmpty()) {
<a name="278" href="#278">278</a>         <em class="jxr_comment">// we are done</em>
<a name="279" href="#279">279</a>         updateCounters();
<a name="280" href="#280">280</a>         <strong class="jxr_keyword">return</strong> false;
<a name="281" href="#281">281</a>       }
<a name="282" href="#282">282</a>       <strong class="jxr_keyword">for</strong> (KeyValue kv : values) {
<a name="283" href="#283">283</a>         <strong class="jxr_keyword">this</strong>.scanMetrics.countOfBytesInResults.inc(kv.getLength());
<a name="284" href="#284">284</a>       }
<a name="285" href="#285">285</a>       <strong class="jxr_keyword">this</strong>.result = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Result.html">Result</a>(values);
<a name="286" href="#286">286</a>       <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.row == <strong class="jxr_keyword">null</strong>) {
<a name="287" href="#287">287</a>         <strong class="jxr_keyword">this</strong>.row = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/io/ImmutableBytesWritable.html">ImmutableBytesWritable</a>();
<a name="288" href="#288">288</a>       }
<a name="289" href="#289">289</a>       <strong class="jxr_keyword">this</strong>.row.set(result.getRow());
<a name="290" href="#290">290</a> 
<a name="291" href="#291">291</a>       <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">true</strong>;
<a name="292" href="#292">292</a>     }
<a name="293" href="#293">293</a> 
<a name="294" href="#294">294</a>     @Override
<a name="295" href="#295">295</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/io/ImmutableBytesWritable.html">ImmutableBytesWritable</a> getCurrentKey() <strong class="jxr_keyword">throws</strong> IOException,
<a name="296" href="#296">296</a>         InterruptedException {
<a name="297" href="#297">297</a>       <strong class="jxr_keyword">return</strong> row;
<a name="298" href="#298">298</a>     }
<a name="299" href="#299">299</a> 
<a name="300" href="#300">300</a>     @Override
<a name="301" href="#301">301</a>     <strong class="jxr_keyword">public</strong> <a href="../../../../../org/apache/hadoop/hbase/client/Result.html">Result</a> getCurrentValue() <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="302" href="#302">302</a>       <strong class="jxr_keyword">return</strong> result;
<a name="303" href="#303">303</a>     }
<a name="304" href="#304">304</a> 
<a name="305" href="#305">305</a>     @Override
<a name="306" href="#306">306</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">float</strong> getProgress() <strong class="jxr_keyword">throws</strong> IOException, InterruptedException {
<a name="307" href="#307">307</a>       <strong class="jxr_keyword">return</strong> 0;
<a name="308" href="#308">308</a>     }
<a name="309" href="#309">309</a> 
<a name="310" href="#310">310</a>     @Override
<a name="311" href="#311">311</a>     <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">void</strong> close() <strong class="jxr_keyword">throws</strong> IOException {
<a name="312" href="#312">312</a>       <strong class="jxr_keyword">try</strong> {
<a name="313" href="#313">313</a>         <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.scanner != <strong class="jxr_keyword">null</strong>) {
<a name="314" href="#314">314</a>           <strong class="jxr_keyword">this</strong>.scanner.close();
<a name="315" href="#315">315</a>         }
<a name="316" href="#316">316</a>       } <strong class="jxr_keyword">finally</strong> {
<a name="317" href="#317">317</a>         <strong class="jxr_keyword">if</strong> (region != <strong class="jxr_keyword">null</strong>) {
<a name="318" href="#318">318</a>           region.closeRegionOperation();
<a name="319" href="#319">319</a>           region.close(<strong class="jxr_keyword">true</strong>);
<a name="320" href="#320">320</a>         }
<a name="321" href="#321">321</a>       }
<a name="322" href="#322">322</a>     }
<a name="323" href="#323">323</a> 
<a name="324" href="#324">324</a>     <em class="jxr_javadoccomment">/**</em>
<a name="325" href="#325">325</a> <em class="jxr_javadoccomment">     * If hbase runs on new version of mapreduce, RecordReader has access to</em>
<a name="326" href="#326">326</a> <em class="jxr_javadoccomment">     * counters thus can update counters based on scanMetrics.</em>
<a name="327" href="#327">327</a> <em class="jxr_javadoccomment">     * If hbase runs on old version of mapreduce, it won't be able to get</em>
<a name="328" href="#328">328</a> <em class="jxr_javadoccomment">     * access to counters and TableRecorderReader can't update counter values.</em>
<a name="329" href="#329">329</a> <em class="jxr_javadoccomment">     * @throws IOException</em>
<a name="330" href="#330">330</a> <em class="jxr_javadoccomment">     */</em>
<a name="331" href="#331">331</a>     <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">void</strong> updateCounters() <strong class="jxr_keyword">throws</strong> IOException {
<a name="332" href="#332">332</a>       <em class="jxr_comment">// we can get access to counters only if hbase uses new mapreduce APIs</em>
<a name="333" href="#333">333</a>       <strong class="jxr_keyword">if</strong> (<strong class="jxr_keyword">this</strong>.getCounter == <strong class="jxr_keyword">null</strong>) {
<a name="334" href="#334">334</a>         <strong class="jxr_keyword">return</strong>;
<a name="335" href="#335">335</a>       }
<a name="336" href="#336">336</a> 
<a name="337" href="#337">337</a>       MetricsTimeVaryingLong[] mlvs =
<a name="338" href="#338">338</a>         scanMetrics.getMetricsTimeVaryingLongArray();
<a name="339" href="#339">339</a> 
<a name="340" href="#340">340</a>       <strong class="jxr_keyword">try</strong> {
<a name="341" href="#341">341</a>         <strong class="jxr_keyword">for</strong> (MetricsTimeVaryingLong mlv : mlvs) {
<a name="342" href="#342">342</a>           <a href="../../../../../org/apache/hadoop/hbase/snapshot/ExportSnapshot.html">Counter</a> ct = (Counter)<strong class="jxr_keyword">this</strong>.getCounter.invoke(context,
<a name="343" href="#343">343</a>             HBASE_COUNTER_GROUP_NAME, mlv.getName());
<a name="344" href="#344">344</a>           ct.increment(mlv.getCurrentIntervalValue());
<a name="345" href="#345">345</a>         }
<a name="346" href="#346">346</a>       } <strong class="jxr_keyword">catch</strong> (Exception e) {
<a name="347" href="#347">347</a>         LOG.debug(<span class="jxr_string">"can't update counter."</span> + StringUtils.stringifyException(e));
<a name="348" href="#348">348</a>       }
<a name="349" href="#349">349</a>     }
<a name="350" href="#350">350</a> 
<a name="351" href="#351">351</a>    <em class="jxr_javadoccomment">/**</em>
<a name="352" href="#352">352</a> <em class="jxr_javadoccomment">     * In new mapreduce APIs, TaskAttemptContext has two getCounter methods</em>
<a name="353" href="#353">353</a> <em class="jxr_javadoccomment">     * Check if getCounter(String, String) method is available.</em>
<a name="354" href="#354">354</a> <em class="jxr_javadoccomment">     * @return The getCounter method or null if not available.</em>
<a name="355" href="#355">355</a> <em class="jxr_javadoccomment">     * @throws IOException</em>
<a name="356" href="#356">356</a> <em class="jxr_javadoccomment">     */</em>
<a name="357" href="#357">357</a>     <strong class="jxr_keyword">private</strong> Method retrieveGetCounterWithStringsParams(TaskAttemptContext context)
<a name="358" href="#358">358</a>     <strong class="jxr_keyword">throws</strong> IOException {
<a name="359" href="#359">359</a>       Method m = <strong class="jxr_keyword">null</strong>;
<a name="360" href="#360">360</a>       <strong class="jxr_keyword">try</strong> {
<a name="361" href="#361">361</a>         m = context.getClass().getMethod(<span class="jxr_string">"getCounter"</span>,
<a name="362" href="#362">362</a>           <strong class="jxr_keyword">new</strong> Class [] {String.<strong class="jxr_keyword">class</strong>, String.<strong class="jxr_keyword">class</strong>});
<a name="363" href="#363">363</a>       } <strong class="jxr_keyword">catch</strong> (SecurityException e) {
<a name="364" href="#364">364</a>         <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IOException(<span class="jxr_string">"Failed test for getCounter"</span>, e);
<a name="365" href="#365">365</a>       } <strong class="jxr_keyword">catch</strong> (NoSuchMethodException e) {
<a name="366" href="#366">366</a>         <em class="jxr_comment">// Ignore</em>
<a name="367" href="#367">367</a>       }
<a name="368" href="#368">368</a>       <strong class="jxr_keyword">return</strong> m;
<a name="369" href="#369">369</a>     }
<a name="370" href="#370">370</a> 
<a name="371" href="#371">371</a>   }
<a name="372" href="#372">372</a> 
<a name="373" href="#373">373</a>   @Override
<a name="374" href="#374">374</a>   <strong class="jxr_keyword">public</strong> RecordReader&lt;ImmutableBytesWritable, Result&gt; createRecordReader(
<a name="375" href="#375">375</a>       <strong class="jxr_keyword">final</strong> InputSplit split, <strong class="jxr_keyword">final</strong> TaskAttemptContext context)
<a name="376" href="#376">376</a>       <strong class="jxr_keyword">throws</strong> IOException {
<a name="377" href="#377">377</a>     <strong class="jxr_keyword">return</strong> <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionRecordReader</a>();
<a name="378" href="#378">378</a>   }
<a name="379" href="#379">379</a> 
<a name="380" href="#380">380</a>   @Override
<a name="381" href="#381">381</a>   <strong class="jxr_keyword">public</strong> List&lt;InputSplit&gt; getSplits(<strong class="jxr_keyword">final</strong> JobContext job) <strong class="jxr_keyword">throws</strong> IOException,
<a name="382" href="#382">382</a>       InterruptedException {
<a name="383" href="#383">383</a>     Configuration conf = job.getConfiguration();
<a name="384" href="#384">384</a>     String snapshotName = getSnapshotName(job.getConfiguration());
<a name="385" href="#385">385</a> 
<a name="386" href="#386">386</a>     Path rootDir = <strong class="jxr_keyword">new</strong> Path(conf.get(HConstants.HBASE_DIR));
<a name="387" href="#387">387</a>     FileSystem fs = rootDir.getFileSystem(conf);
<a name="388" href="#388">388</a> 
<a name="389" href="#389">389</a>     Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(
<a name="390" href="#390">390</a>         snapshotName, rootDir);
<a name="391" href="#391">391</a> 
<a name="392" href="#392">392</a>     Set&lt;String&gt; snapshotRegionNames = <a href="../../../../../org/apache/hadoop/hbase/snapshot/SnapshotReferenceUtil.html">SnapshotReferenceUtil</a>
<a name="393" href="#393">393</a>         .getSnapshotRegionNames(fs, snapshotDir);
<a name="394" href="#394">394</a>     <strong class="jxr_keyword">if</strong> (snapshotRegionNames == <strong class="jxr_keyword">null</strong>) {
<a name="395" href="#395">395</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IllegalArgumentException(<span class="jxr_string">"Snapshot is empty"</span>);
<a name="396" href="#396">396</a>     }
<a name="397" href="#397">397</a> 
<a name="398" href="#398">398</a>     <em class="jxr_comment">// load table descriptor</em>
<a name="399" href="#399">399</a>     <a href="../../../../../org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a> htd = FSTableDescriptors.getTableDescriptor(fs,
<a name="400" href="#400">400</a>         snapshotDir);
<a name="401" href="#401">401</a> 
<a name="402" href="#402">402</a>     <a href="../../../../../org/apache/hadoop/hbase/client/Scan.html">Scan</a> scan = TableMapReduceUtil.convertStringToScan(conf.get(TableInputFormat.SCAN));
<a name="403" href="#403">403</a>     Path tableDir = <strong class="jxr_keyword">new</strong> Path(conf.get(TABLE_DIR_KEY));
<a name="404" href="#404">404</a> 
<a name="405" href="#405">405</a>     List&lt;InputSplit&gt; splits = <strong class="jxr_keyword">new</strong> ArrayList&lt;InputSplit&gt;(
<a name="406" href="#406">406</a>         snapshotRegionNames.size());
<a name="407" href="#407">407</a>     <strong class="jxr_keyword">for</strong> (String regionName : snapshotRegionNames) {
<a name="408" href="#408">408</a>       <em class="jxr_comment">// load region descriptor</em>
<a name="409" href="#409">409</a>       Path regionDir = <strong class="jxr_keyword">new</strong> Path(snapshotDir, regionName);
<a name="410" href="#410">410</a>       <a href="../../../../../org/apache/hadoop/hbase/HRegionInfo.html">HRegionInfo</a> hri = HRegion.loadDotRegionInfoFileContent(fs, regionDir);
<a name="411" href="#411">411</a> 
<a name="412" href="#412">412</a>       <strong class="jxr_keyword">if</strong> (keyRangesOverlap(scan.getStartRow(), scan.getStopRow(),
<a name="413" href="#413">413</a>           hri.getStartKey(), hri.getEndKey())) {
<a name="414" href="#414">414</a>         <em class="jxr_comment">// compute HDFS locations from snapshot files (which will get the locations for</em>
<a name="415" href="#415">415</a>         <em class="jxr_comment">// referred hfiles)</em>
<a name="416" href="#416">416</a>         List&lt;String&gt; hosts = getBestLocations(conf,
<a name="417" href="#417">417</a>           HRegion.computeHDFSBlocksDistribution(conf, htd, hri.getEncodedName(), tableDir));
<a name="418" href="#418">418</a> 
<a name="419" href="#419">419</a>         <strong class="jxr_keyword">int</strong> len = Math.min(3, hosts.size());
<a name="420" href="#420">420</a>         hosts = hosts.subList(0, len);
<a name="421" href="#421">421</a>         splits.add(<strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/mapreduce/TableSnapshotInputFormat.html">TableSnapshotRegionSplit</a>(regionName, hosts));
<a name="422" href="#422">422</a>       }
<a name="423" href="#423">423</a>     }
<a name="424" href="#424">424</a> 
<a name="425" href="#425">425</a>     <strong class="jxr_keyword">return</strong> splits;
<a name="426" href="#426">426</a>   }
<a name="427" href="#427">427</a> 
<a name="428" href="#428">428</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">boolean</strong> keyRangesOverlap(<strong class="jxr_keyword">final</strong> byte[] start1, <strong class="jxr_keyword">final</strong> byte[] end1,
<a name="429" href="#429">429</a>       <strong class="jxr_keyword">final</strong> byte[] start2, <strong class="jxr_keyword">final</strong> byte[] end2) {
<a name="430" href="#430">430</a>     <strong class="jxr_keyword">return</strong> (end2.length == 0 || start1.length == 0 || Bytes.compareTo(start1,
<a name="431" href="#431">431</a>         end2) &lt; 0)
<a name="432" href="#432">432</a>         &amp;&amp; (end1.length == 0 || start2.length == 0 || Bytes.compareTo(start2,
<a name="433" href="#433">433</a>             end1) &lt; 0);
<a name="434" href="#434">434</a>   }
<a name="435" href="#435">435</a> 
<a name="436" href="#436">436</a>   <em class="jxr_javadoccomment">/**</em>
<a name="437" href="#437">437</a> <em class="jxr_javadoccomment">   * This computes the locations to be passed from the InputSplit. MR/Yarn schedulers does not take</em>
<a name="438" href="#438">438</a> <em class="jxr_javadoccomment">   * weights into account, thus will treat every location passed from the input split as equal. We</em>
<a name="439" href="#439">439</a> <em class="jxr_javadoccomment">   * do not want to blindly pass all the locations, since we are creating one split per region, and</em>
<a name="440" href="#440">440</a> <em class="jxr_javadoccomment">   * the region's blocks are all distributed throughout the cluster unless favorite node assignment</em>
<a name="441" href="#441">441</a> <em class="jxr_javadoccomment">   * is used. On the expected stable case, only one location will contain most of the blocks as </em>
<a name="442" href="#442">442</a> <em class="jxr_javadoccomment">   * local.</em>
<a name="443" href="#443">443</a> <em class="jxr_javadoccomment">   * On the other hand, in favored node assignment, 3 nodes will contain highly local blocks. Here</em>
<a name="444" href="#444">444</a> <em class="jxr_javadoccomment">   * we are doing a simple heuristic, where we will pass all hosts which have at least 80%</em>
<a name="445" href="#445">445</a> <em class="jxr_javadoccomment">   * (hbase.tablesnapshotinputformat.locality.cutoff.multiplier) as much block locality as the top</em>
<a name="446" href="#446">446</a> <em class="jxr_javadoccomment">   * host with the best locality.</em>
<a name="447" href="#447">447</a> <em class="jxr_javadoccomment">   */</em>
<a name="448" href="#448">448</a>   @VisibleForTesting
<a name="449" href="#449">449</a>   List&lt;String&gt; getBestLocations(Configuration conf, <a href="../../../../../org/apache/hadoop/hbase/HDFSBlocksDistribution.html">HDFSBlocksDistribution</a> blockDistribution) {
<a name="450" href="#450">450</a>     List&lt;String&gt; locations = <strong class="jxr_keyword">new</strong> ArrayList&lt;String&gt;(3);
<a name="451" href="#451">451</a> 
<a name="452" href="#452">452</a>     <a href="../../../../../org/apache/hadoop/hbase/HDFSBlocksDistribution.html">HostAndWeight</a>[] hostAndWeights = blockDistribution.getTopHostsWithWeights();
<a name="453" href="#453">453</a> 
<a name="454" href="#454">454</a>     <strong class="jxr_keyword">if</strong> (hostAndWeights.length == 0) {
<a name="455" href="#455">455</a>       <strong class="jxr_keyword">return</strong> locations;
<a name="456" href="#456">456</a>     }
<a name="457" href="#457">457</a> 
<a name="458" href="#458">458</a>     <a href="../../../../../org/apache/hadoop/hbase/HDFSBlocksDistribution.html">HostAndWeight</a> topHost = hostAndWeights[0];
<a name="459" href="#459">459</a>     locations.add(topHost.getHost());
<a name="460" href="#460">460</a> 
<a name="461" href="#461">461</a>     <em class="jxr_comment">// Heuristic: filter all hosts which have at least cutoffMultiplier % of block locality</em>
<a name="462" href="#462">462</a>     <strong class="jxr_keyword">double</strong> cutoffMultiplier
<a name="463" href="#463">463</a>       = conf.getFloat(LOCALITY_CUTOFF_MULTIPLIER, DEFAULT_LOCALITY_CUTOFF_MULTIPLIER);
<a name="464" href="#464">464</a> 
<a name="465" href="#465">465</a>     <strong class="jxr_keyword">double</strong> filterWeight = topHost.getWeight() * cutoffMultiplier;
<a name="466" href="#466">466</a> 
<a name="467" href="#467">467</a>     <strong class="jxr_keyword">for</strong> (<strong class="jxr_keyword">int</strong> i = 1; i &lt; hostAndWeights.length; i++) {
<a name="468" href="#468">468</a>       <strong class="jxr_keyword">if</strong> (hostAndWeights[i].getWeight() &gt;= filterWeight) {
<a name="469" href="#469">469</a>         locations.add(hostAndWeights[i].getHost());
<a name="470" href="#470">470</a>       } <strong class="jxr_keyword">else</strong> {
<a name="471" href="#471">471</a>         <strong class="jxr_keyword">break</strong>;
<a name="472" href="#472">472</a>       }
<a name="473" href="#473">473</a>     }
<a name="474" href="#474">474</a> 
<a name="475" href="#475">475</a>     <strong class="jxr_keyword">return</strong> locations;
<a name="476" href="#476">476</a>   }
<a name="477" href="#477">477</a> 
<a name="478" href="#478">478</a>   <em class="jxr_javadoccomment">/**</em>
<a name="479" href="#479">479</a> <em class="jxr_javadoccomment">   * Set job input.</em>
<a name="480" href="#480">480</a> <em class="jxr_javadoccomment">   * </em>
<a name="481" href="#481">481</a> <em class="jxr_javadoccomment">   * @param job</em>
<a name="482" href="#482">482</a> <em class="jxr_javadoccomment">   *          The job</em>
<a name="483" href="#483">483</a> <em class="jxr_javadoccomment">   * @param snapshotName</em>
<a name="484" href="#484">484</a> <em class="jxr_javadoccomment">   *          The snapshot name</em>
<a name="485" href="#485">485</a> <em class="jxr_javadoccomment">   * @param restoreDir</em>
<a name="486" href="#486">486</a> <em class="jxr_javadoccomment">   *          The directory where the temp table will be created</em>
<a name="487" href="#487">487</a> <em class="jxr_javadoccomment">   * @throws IOException</em>
<a name="488" href="#488">488</a> <em class="jxr_javadoccomment">   *           on error</em>
<a name="489" href="#489">489</a> <em class="jxr_javadoccomment">   */</em>
<a name="490" href="#490">490</a>   <strong class="jxr_keyword">public</strong> <strong class="jxr_keyword">static</strong> <strong class="jxr_keyword">void</strong> setInput(<strong class="jxr_keyword">final</strong> Job job, <strong class="jxr_keyword">final</strong> String snapshotName,
<a name="491" href="#491">491</a>       <strong class="jxr_keyword">final</strong> Path restoreDir) <strong class="jxr_keyword">throws</strong> IOException {
<a name="492" href="#492">492</a>     Configuration conf = job.getConfiguration();
<a name="493" href="#493">493</a>     conf.set(SNAPSHOT_NAME_KEY, snapshotName);
<a name="494" href="#494">494</a> 
<a name="495" href="#495">495</a>     Path rootDir = <strong class="jxr_keyword">new</strong> Path(conf.get(HConstants.HBASE_DIR));
<a name="496" href="#496">496</a>     FileSystem fs = rootDir.getFileSystem(conf);
<a name="497" href="#497">497</a> 
<a name="498" href="#498">498</a>     Path snapshotDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(
<a name="499" href="#499">499</a>         snapshotName, rootDir);
<a name="500" href="#500">500</a>     SnapshotDescription snapshotDesc = <a href="../../../../../org/apache/hadoop/hbase/snapshot/SnapshotDescriptionUtils.html">SnapshotDescriptionUtils</a>
<a name="501" href="#501">501</a>         .readSnapshotInfo(fs, snapshotDir);
<a name="502" href="#502">502</a> 
<a name="503" href="#503">503</a>     <em class="jxr_comment">// load table descriptor</em>
<a name="504" href="#504">504</a>     <a href="../../../../../org/apache/hadoop/hbase/HTableDescriptor.html">HTableDescriptor</a> htd = FSTableDescriptors.getTableDescriptor(fs,
<a name="505" href="#505">505</a>         snapshotDir);
<a name="506" href="#506">506</a> 
<a name="507" href="#507">507</a>     Path tableDir = <strong class="jxr_keyword">new</strong> Path(restoreDir, htd.getNameAsString());
<a name="508" href="#508">508</a>     conf.set(TABLE_DIR_KEY, tableDir.toString());
<a name="509" href="#509">509</a> 
<a name="510" href="#510">510</a>     <a href="../../../../../org/apache/hadoop/hbase/monitoring/MonitoredTask.html">MonitoredTask</a> status = TaskMonitor.get().createStatus(
<a name="511" href="#511">511</a>         <span class="jxr_string">"Restoring  snapshot '"</span> + snapshotName + <span class="jxr_string">"' to directory "</span> + tableDir);
<a name="512" href="#512">512</a>     <a href="../../../../../org/apache/hadoop/hbase/errorhandling/ForeignExceptionDispatcher.html">ForeignExceptionDispatcher</a> monitor = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/errorhandling/ForeignExceptionDispatcher.html">ForeignExceptionDispatcher</a>();
<a name="513" href="#513">513</a> 
<a name="514" href="#514">514</a>     <a href="../../../../../org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.html">RestoreSnapshotHelper</a> helper = <strong class="jxr_keyword">new</strong> <a href="../../../../../org/apache/hadoop/hbase/snapshot/RestoreSnapshotHelper.html">RestoreSnapshotHelper</a>(conf, fs,
<a name="515" href="#515">515</a>         snapshotDesc, snapshotDir, htd, tableDir, monitor, status);
<a name="516" href="#516">516</a>     helper.restoreHdfsRegions();
<a name="517" href="#517">517</a>   }
<a name="518" href="#518">518</a> 
<a name="519" href="#519">519</a>   <strong class="jxr_keyword">private</strong> <strong class="jxr_keyword">static</strong> String getSnapshotName(<strong class="jxr_keyword">final</strong> Configuration conf) {
<a name="520" href="#520">520</a>     String snapshotName = conf.get(SNAPSHOT_NAME_KEY);
<a name="521" href="#521">521</a>     <strong class="jxr_keyword">if</strong> (snapshotName == <strong class="jxr_keyword">null</strong>) {
<a name="522" href="#522">522</a>       <strong class="jxr_keyword">throw</strong> <strong class="jxr_keyword">new</strong> IllegalArgumentException(<span class="jxr_string">"Snapshot name must be provided"</span>);
<a name="523" href="#523">523</a>     }
<a name="524" href="#524">524</a>     <strong class="jxr_keyword">return</strong> snapshotName;
<a name="525" href="#525">525</a>   }
<a name="526" href="#526">526</a> }
<a name="527" href="#527">527</a> 
</pre>
<hr/><div id="footer">This page was automatically generated by <a href="http://maven.apache.org/">Maven</a></div></body>
</html>

